# 待办事项

- [ ] 发布到 Windsurf、Cursor 和 IntelliJ IDEA 插件市场
- [ ] 提升上下文感知能力，增加上下文传递策略
  - [ ] 开发一个上下文提取模块，分析项目结构、代码风格和历史数据
  - [ ] 将上下文信息嵌入 AI 输入，提升建议质量
- [ ] 支持自定义模型
- [ ] 支持本地模型选项。硬件要求：确保插件对用户机器的性能要求合理，比如提供“轻量模式”和“增强模式”选项，让用户根据硬件选择运行方式。
  - 选择轻量级模型：使用针对代码分析优化的模型，如 CodeBERT 或 GraphCodeBERT 的精简版本。这些模型可以微调为代码审查任务。
  - 本地推理引擎：集成一个本地推理框架，比如 ONNX Runtime 或 TensorFlow Lite，支持模型快速运行。
- [ ] 优化数据传输和处理方式，减少对云端 API 的依赖，同时提高效率。核心思路是增量分析和分块处理，只传输必要的数据。
- [ ] 本地预处理
  - 在本地对代码进行预处理，提取关键信息（如函数定义、变量使用等），然后将精简后的数据传给 AI，进一步降低传输负担。
  - 代码嵌入技术：使用 Code2Vec 或类似技术，将项目代码转为向量表示，作为上下文输入 AI 模型。
  - 项目元数据：在 AI 请求中包含项目的基本信息，如编程语言、框架、依赖库等。
